{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnQGohGx5FPxe12oWjQKem",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trinhtin/ecommerce-research/blob/main/GroqCloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FrmcGPtAzu3H",
        "outputId": "d6070a25-741f-4013-b6ea-bbc87d04bc22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTMHuCxbythh",
        "outputId": "c8ebcb07-7894-4bff-80a7-0e413579afa8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key= userdata.get('GROQ_API_KEY'),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Gợi ý dàn ý viết báo về chủ đề Tạo câu hỏi trắc nghiệm với RAG, LLM\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJQ64qryvYr",
        "outputId": "5a5e01aa-685c-4965-f6ca-7493dd43d1ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a suggested outline for a reporting article on creating multiple-choice questions with RAG, LLM:\n",
            "\n",
            "**Title:** \"Revolutionizing Assessment: How RAG and LLM Boost the Accuracy of Multiple-Choice Questions\"\n",
            "\n",
            "**Introduction:**\n",
            "\n",
            "* Briefly introduce the importance of multiple-choice questions in language assessment\n",
            "* Explain the limitations of traditional methods in creating such questions\n",
            "* Introduce RAG (Radiant Age Graph) and LLM (Large Language Model) as game-changers in creating high-precision multiple-choice questions\n",
            "\n",
            "**What is RAG?**\n",
            "\n",
            "* Define RAG and its role in language assessment\n",
            "* Explain how RAG helps in generating relevant and accurate statements for multiple-choice questions\n",
            "\n",
            "**How does LLM work?**\n",
            "\n",
            "* Introduce LLM and its capabilities in processing and analyzing vast amounts of language data\n",
            "* Explain how LLM helps in identifying potential distractors, making it easier to create precise multiple-choice questions\n",
            "\n",
            "**Combining RAG and LLM: The Future of Language Assessment**\n",
            "\n",
            "* Discuss the benefits of combining RAG and LLM in creating multiple-choice questions\n",
            "* Highlight examples of how this collaboration can revolutionize language assessment\n",
            "\n",
            "**Case Studies:**\n",
            "\n",
            "* Provide concrete examples of using RAG and LLM in creating multiple-choice questions for different language assessments (e.g., proficiency exams, language learners' tests)\n",
            "\n",
            "**Expert Insights:**\n",
            "\n",
            "* Interview a language assessment expert or a researcher who has worked on RAG or LLM-based multiple-choice questions to gain insights on their experiences and challenges\n",
            "* Quote the expert on the potential impact of RAG and LLM on language assessment\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "* Summarize the benefits of using RAG and LLM in creating multiple-choice questions\n",
            "* Emphasize the potential for improved accuracy and reliability in language assessment\n",
            "* End with a thought-provoking question or a call to action for the readers\n",
            "\n",
            "**Additional suggestions:**\n",
            "\n",
            "* Include visual aids such as flowcharts, diagrams, or infographics to illustrate the process of creating multiple-choice questions with RAG and LLM\n",
            "* Provide a simple example of a multiple-choice question generated using RAG and LLM\n",
            "* Discuss potential challenges and limitations of using RAG and LLM in language assessment and ways to address them\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key= userdata.get('GROQ_API_KEY'),\n",
        ")\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Vector DB nào tốt nhất \"\n",
        "        },\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekgLWvvD1BL2",
        "outputId": "3451aaa2-255d-4114-a80b-39a85635a84f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector DB (Vector Database) là một loại cơ sở dữ liệu được thiết kế để lưu trữ và tìm kiếm các vectơ, thường được sử dụng trong các ứng dụng như tìm kiếm hình ảnh, tìm kiếm văn bản, và các ứng dụng khác liên quan đến việc tìm kiếm các vectơ tương tự.\n",
            "\n",
            "Có nhiều Vector DB khác nhau có sẵn, mỗi loại có những đặc điểm và tính năng riêng biệt. Dưới đây là một số Vector DB phổ biến:\n",
            "\n",
            "1. **Annoy (Approximate Nearest Neighbors)**: Annoy là một thư viện mã nguồn mở được thiết kế để tìm kiếm các vectơ tương tự trong không gian đa chiều. Nó sử dụng các thuật toán như Approximate Nearest Neighbors (ANN) để tìm kiếm các vectơ tương tự.\n",
            "2. **Faiss (Facebook AI Similarity Search)**: Faiss là một thư viện mã nguồn mở được phát triển bởi Facebook, được thiết kế để tìm kiếm các vectơ tương tự trong không gian đa chiều. Nó sử dụng các thuật toán như k-means, k-NN, và các thuật toán khác để tìm kiếm các vectơ tương tự.\n",
            "3. **Hnswlib (Hierarchical Navigating with Suffix Trees)**: Hnswlib là một thư viện mã nguồn mở được thiết kế để tìm kiếm các vectơ tương tự trong không gian đa chiều. Nó sử dụng các thuật toán như Hnsw (Hierarchical Navigating with Suffix Trees) để tìm kiếm các vectơ tương tự.\n",
            "4. **Pinecone**: Pinecone là một Vector DB được thiết kế để tìm kiếm các vectơ tương tự trong không gian đa chiều. Nó sử dụng các thuật toán như k-means, k-NN, và các thuật toán khác để tìm kiếm các vectơ tương tự.\n",
            "5. **Milvus**: Milvus là một Vector DB được thiết kế để tìm kiếm các vectơ tương tự trong không gian đa chiều. Nó sử dụng các thuật toán như k-means, k-NN, và các thuật toán khác để tìm kiếm các vectơ tương tự.\n",
            "\n",
            "Để chọn Vector DB tốt nhất, bạn cần xem xét các yếu tố sau:\n",
            "\n",
            "* **Tốc độ tìm kiếm**: Vector DB nào có tốc độ tìm kiếm nhanh nhất?\n",
            "* **Độ chính xác**: Vector DB nào có độ chính xác cao nhất?\n",
            "* **Khả năng mở rộng**: Vector DB nào có khả năng mở rộng cao nhất?\n",
            "* **Tính năng**: Vector DB nào có tính năng phù hợp với nhu cầu của bạn?\n",
            "\n",
            "Dưới đây là một số gợi ý để chọn Vector DB:\n",
            "\n",
            "* Nếu bạn cần tốc độ tìm kiếm nhanh, bạn có thể chọn Annoy hoặc Faiss.\n",
            "* Nếu bạn cần độ chính xác cao, bạn có thể chọn Hnswlib hoặc Pinecone.\n",
            "* Nếu bạn cần khả năng mở rộng cao, bạn có thể chọn Milvus.\n",
            "* Nếu bạn cần tính năng đa dạng, bạn có thể chọn Faiss hoặc Pinecone.\n",
            "\n",
            "Tóm lại, Vector DB nào tốt nhất phụ thuộc vào nhu cầu và yêu cầu của bạn. Bạn cần xem xét các yếu tố trên và chọn Vector DB phù hợp với nhu cầu của bạn."
          ]
        }
      ]
    }
  ]
}